# ğŸ“š DocumentaciÃ³n TÃ©cnica Completa - Agente Capital Plus

## Tabla de Contenidos

1. [IntroducciÃ³n](#introducciÃ³n)
2. [Arquitectura General](#arquitectura-general)
3. [Sistema de Embeddings y Pinecone](#sistema-de-embeddings-y-pinecone)
4. [Procesamiento de Documentos](#procesamiento-de-documentos)
5. [Sistema RAG (Retrieval Augmented Generation)](#sistema-rag)
6. [AutenticaciÃ³n y Seguridad](#autenticaciÃ³n-y-seguridad)
7. [Base de Datos PostgreSQL](#base-de-datos-postgresql)
8. [Proveedores LLM](#proveedores-llm)
9. [Sistema de CachÃ©](#sistema-de-cachÃ©)
10. [Sistema de Aprendizaje](#sistema-de-aprendizaje)
11. [Flujos Completos](#flujos-completos)
12. [Conexiones y ConfiguraciÃ³n](#conexiones-y-configuraciÃ³n)

---

## IntroducciÃ³n

**Agente Capital Plus** es un sistema completo de RAG (Retrieval Augmented Generation) diseÃ±ado para proporcionar respuestas inteligentes basadas en documentos corporativos. El sistema utiliza embeddings vectoriales, bÃºsqueda semÃ¡ntica y modelos de lenguaje para responder consultas sobre desarrollos inmobiliarios, polÃ­ticas, precios e inventario.

### TecnologÃ­as Principales

- **Framework**: Next.js 14 (App Router)
- **Lenguaje**: TypeScript 5.3
- **Base de Datos**: PostgreSQL 15
- **Vector DB**: Pinecone (con Inference API)
- **Embeddings**: llama-text-embed-v2 (1024 dimensiones)
- **LLM**: LM Studio (local) / OpenAI (cloud)
- **AutenticaciÃ³n**: JWT (jsonwebtoken)
- **Procesamiento PDF**: pdf-parse, pdfjs-dist
- **OCR**: Tesseract.js (temporalmente deshabilitado)

---

## Arquitectura General

### Diagrama de Componentes

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FRONTEND (Next.js)                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Dashboardâ”‚  â”‚  Agent   â”‚  â”‚ Documentsâ”‚  â”‚  Config  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚             â”‚             â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    API ROUTES (Next.js)   â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
        â”‚  â”‚ /api/rag-query      â”‚  â”‚
        â”‚  â”‚ /api/upload         â”‚  â”‚
        â”‚  â”‚ /api/auth/*         â”‚  â”‚
        â”‚  â”‚ /api/documents/*    â”‚  â”‚
        â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚ â”‚ Pinecone â”‚ â”‚  LLM Providerâ”‚
â”‚              â”‚ â”‚          â”‚ â”‚              â”‚
â”‚ - Users      â”‚ â”‚ - Vectorsâ”‚ â”‚ - LM Studio  â”‚
â”‚ - Documents  â”‚ â”‚ - Metadataâ”‚ â”‚ - OpenAI    â”‚
â”‚ - Logs       â”‚ â”‚ - Namespacesâ”‚ â”‚              â”‚
â”‚ - Cache      â”‚ â”‚          â”‚ â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo de Datos Principal

1. **Upload de Documentos**:
   - Usuario sube PDF/CSV/DOCX â†’ ExtracciÃ³n de texto â†’ Chunking â†’ Embeddings â†’ Pinecone

2. **Consulta RAG**:
   - Usuario hace pregunta â†’ Procesamiento de query â†’ Embedding del query â†’ BÃºsqueda en Pinecone â†’ ConstrucciÃ³n de contexto â†’ LLM â†’ Respuesta

3. **CachÃ©**:
   - Consultas similares â†’ BÃºsqueda en cachÃ© â†’ Si existe, retornar; si no, procesar y guardar

---

## Sistema de Embeddings y Pinecone

### ConfiguraciÃ³n de Embeddings

El sistema utiliza **Pinecone Inference API** con el modelo **llama-text-embed-v2** para generar embeddings.

#### CaracterÃ­sticas TÃ©cnicas

- **Modelo**: `llama-text-embed-v2`
- **Dimensiones**: 1024
- **MÃ©trica**: Cosine Similarity
- **Input Types**:
  - `passage`: Para documentos/chunks (al subir)
  - `query`: Para consultas de bÃºsqueda

#### Proceso de GeneraciÃ³n de Embeddings

**1. Para Documentos (Upload)**

```typescript
// UbicaciÃ³n: src/lib/pinecone.ts - funciÃ³n upsertChunks()

// Paso 1: Generar embeddings en batches
const client = await initPinecone();
const embeddings = await client.inference.embed(
  'llama-text-embed-v2',
  textBatch,              // Array de textos
  { inputType: 'passage' } // Tipo: documento
);

// Paso 2: Crear records con vectores
const records = chunks.map((chunk, idx) => ({
  id: chunk.id,
  values: allEmbeddings[idx].values, // Vector de 1024 dimensiones
  metadata: { /* metadatos del chunk */ }
}));

// Paso 3: Subir a Pinecone
await index.namespace(namespace).upsert(records);
```

**2. Para Consultas (RAG Query)**

```typescript
// UbicaciÃ³n: src/lib/pinecone.ts - funciÃ³n queryChunks()

// Paso 1: Procesar query (correcciÃ³n ortogrÃ¡fica + expansiÃ³n semÃ¡ntica)
const processedQuery = processQuery(queryText);

// Paso 2: Generar embedding del query
const embeddings = await client.inference.embed(
  'llama-text-embed-v2',
  [processedQuery],
  { inputType: 'query' } // Tipo: consulta
);

// Paso 3: Buscar vectores similares
const response = await index.namespace(namespace).query({
  vector: queryVector,
  topK: topK * 2, // Buscar mÃ¡s para re-ranking
  filter: { development, type },
  includeMetadata: true
});
```

### Estructura de Namespaces en Pinecone

Los namespaces organizan los vectores por **zona geogrÃ¡fica**:

- `yucatan` - Documentos de YucatÃ¡n
- `puebla` - Documentos de Puebla
- `quintana_roo` - Documentos de Quintana Roo
- `cache` - CachÃ© de consultas (namespace especial)

### Metadata de Chunks

Cada vector en Pinecone incluye metadata:

```typescript
{
  text: string;              // Texto original del chunk
  zone: Zone;                // Zona geogrÃ¡fica
  development: string;       // Nombre del desarrollo
  type: DocumentContentType; // Tipo de documento (brochure, policy, etc.)
  page: number;              // NÃºmero de pÃ¡gina
  chunk: number;             // NÃºmero de chunk en la pÃ¡gina
  sourceFileName: string;    // Nombre del archivo fuente
  uploaded_by: number;       // ID del usuario que subiÃ³
  created_at: string;        // Fecha de creaciÃ³n
}
```

### Re-ranking Inteligente

El sistema aplica re-ranking basado en estadÃ­sticas de chunks:

```typescript
// Calcular score final: similarity_score * 0.8 + success_ratio * 0.2
const finalScore = (match.score * 0.8) + (successRatio * 0.2);
```

Esto prioriza chunks que han sido Ãºtiles en consultas anteriores.

### BÃºsqueda con Variantes

Si la bÃºsqueda inicial no encuentra suficientes resultados relevantes, el sistema:

1. Genera variantes del query usando `generateQueryVariants()`
2. Busca con las 2-3 mejores variantes
3. Combina resultados y elimina duplicados
4. Retorna los mejores matches

---

## Procesamiento de Documentos

### Flujo Completo de Upload

```
1. Usuario sube archivo (PDF/CSV/DOCX)
   â†“
2. ValidaciÃ³n de archivo (tamaÃ±o, tipo)
   â†“
3. VerificaciÃ³n de permisos del usuario
   â†“
4. Guardado temporal del archivo
   â†“
5. ExtracciÃ³n de texto segÃºn tipo:
   - PDF: pdf-parse â†’ Si falla, intenta OCR
   - CSV: ConversiÃ³n a texto estructurado
   - DOCX: mammoth.extractRawText()
   â†“
6. Limpieza de texto (eliminar caracteres especiales, normalizar)
   â†“
7. Chunking inteligente (con overlap)
   â†“
8. GeneraciÃ³n de embeddings (Pinecone Inference API)
   â†“
9. Subida a Pinecone (con metadata)
   â†“
10. Guardado de metadata en PostgreSQL
   â†“
11. Registro de acciÃ³n en logs
   â†“
12. Limpieza de archivo temporal
```

### ExtracciÃ³n de Texto

#### PDF

```typescript
// UbicaciÃ³n: src/app/api/upload/route.ts

// MÃ©todo 1: ExtracciÃ³n estÃ¡ndar (rÃ¡pida)
const standardText = await extractTextFromPDF(dataBuffer);

// MÃ©todo 2: OCR (si el PDF es escaneado)
if (needsOCR(standardText)) {
  const ocrText = await extractTextFromPDFWithOCR(filepath);
}
```

**DetecciÃ³n de necesidad de OCR**:
- Si el texto extraÃ­do tiene menos de 50 caracteres por pÃ¡gina
- Si contiene principalmente caracteres no reconocibles

**Nota**: El OCR estÃ¡ temporalmente deshabilitado debido a problemas de compatibilidad en Vercel.

#### CSV

```typescript
// ConversiÃ³n de CSV a texto estructurado
const lines = content.split('\n');
const headers = lines[0].split(',');
// Crear pares clave-valor para cada fila
```

#### DOCX

```typescript
// Usando mammoth para extraer texto
const result = await mammoth.extractRawText({ path: filepath });
return result.value;
```

### Chunking Inteligente

El sistema divide documentos en chunks con las siguientes caracterÃ­sticas:

#### ConfiguraciÃ³n

- **TamaÃ±o por defecto**: 500 tokens (~2000 caracteres)
- **Overlap**: 50 tokens (~200 caracteres)
- **Estrategia**: JerÃ¡rquica (pÃ¡rrafos â†’ oraciones â†’ palabras)

#### Algoritmo de Chunking

```typescript
// UbicaciÃ³n: src/lib/chunker.ts

1. Dividir por pÃ¡rrafos (doble salto de lÃ­nea)
2. Si un pÃ¡rrafo cabe en el chunk actual, agregarlo
3. Si no cabe:
   - Guardar chunk actual
   - Mantener overlap (Ãºltimos 50 tokens)
   - Iniciar nuevo chunk con overlap + nuevo pÃ¡rrafo
4. Si un pÃ¡rrafo es muy largo, dividir por oraciones
5. Si una oraciÃ³n es muy larga, dividir por palabras
```

#### GeneraciÃ³n de IDs de Chunks

```typescript
function generateChunkId(filename: string, chunkIndex: number): string {
  const cleanFilename = filename.replace(/[^a-zA-Z0-9]/g, '_').toLowerCase();
  const shortUuid = uuidv4().split('-')[0];
  return `${cleanFilename}_chunk${chunkIndex}_${shortUuid}`;
}
```

### Limpieza de Texto

Cada tipo de archivo tiene su funciÃ³n de limpieza:

- **PDF**: Elimina caracteres de control, normaliza espacios
- **CSV**: Convierte a formato legible con pares clave-valor
- **DOCX**: Limpia caracteres especiales de Word

---

## Sistema RAG

### Flujo Completo de una Consulta RAG

```
1. Usuario envÃ­a consulta
   â†“
2. AutenticaciÃ³n y validaciÃ³n
   â†“
3. VerificaciÃ³n de permisos (zona, desarrollo)
   â†“
4. DetecciÃ³n de consulta simple (saludo, pregunta general)
   â†“
5. Si es simple:
   â†’ Responder directamente sin bÃºsqueda RAG
   â†“
6. Si es compleja:
   â†’ Procesar query (correcciÃ³n + expansiÃ³n)
   â†“
7. Buscar en cachÃ© (por hash exacto o similitud semÃ¡ntica)
   â†“
8. Si estÃ¡ en cachÃ©:
   â†’ Retornar respuesta del cachÃ©
   â†“
9. Si no estÃ¡ en cachÃ©:
   â†’ Generar embedding del query
   â†’ Buscar en Pinecone (topK chunks)
   â†’ Re-ranking con estadÃ­sticas
   â†’ Construir contexto
   â†“
10. Cargar memoria operativa del agente
   â†“
11. Enviar al LLM:
    - System prompt (con memorias)
    - Contexto recuperado
    - Query del usuario
   â†“
12. Recibir respuesta del LLM
   â†“
13. Construir referencias de fuentes
   â†“
14. Guardar en cachÃ©
   â†“
15. Guardar log de consulta
   â†“
16. Registrar chunks usados
   â†“
17. Retornar respuesta al usuario
```

### DetecciÃ³n de Consultas Simples

El sistema detecta consultas que no requieren bÃºsqueda RAG:

```typescript
// Patrones de consultas simples:
- Saludos: "hola", "buenos dÃ­as", "hi"
- Preguntas muy cortas: menos de 10 caracteres
- Preguntas sobre el sistema: "quiÃ©n eres", "quÃ© puedes hacer"
```

Si es simple, se responde directamente con `runSimpleQuery()` que usa un prompt mÃ¡s corto y creativo.

### Procesamiento de Queries

#### CorrecciÃ³n OrtogrÃ¡fica

```typescript
// UbicaciÃ³n: src/lib/queryProcessing.ts

const SPELLING_CORRECTIONS = {
  'contruir': 'construir',
  'contrucciÃ³n': 'construcciÃ³n',
  'canceleria': 'cancelarÃ­a',
  // ... mÃ¡s correcciones
};
```

#### ExpansiÃ³n SemÃ¡ntica

```typescript
const SEMANTIC_EXPANSIONS = {
  'material prohibido': [
    'materiales prohibidos',
    'materiales no permitidos',
    'se prohÃ­be',
    'no se permite'
  ],
  // ... mÃ¡s expansiones
};
```

El sistema expande queries para encontrar informaciÃ³n relacionada que puede estar expresada de diferentes formas en los documentos.

### ConstrucciÃ³n de Contexto

```typescript
// UbicaciÃ³n: src/lib/pinecone.ts - buildContextFromMatches()

const context = matches
  .map((match, index) => {
    return `[Fuente ${index + 1}: ${sourceFileName}, PÃ¡gina ${page}]\n${text}`;
  })
  .join('\n\n---\n\n');
```

Cada fuente se numera para permitir citas en la respuesta.

### System Prompt

El system prompt incluye:

1. **Identidad del agente**: Agente Interno de Capital Plus
2. **Responsabilidades**: Desarrollos, polÃ­ticas, zonas
3. **Reglas de comportamiento**: PrecisiÃ³n, profesionalismo, claridad
4. **Restricciones**: No inventar informaciÃ³n, no asesorÃ­a legal
5. **Formato de respuestas**: Markdown obligatorio
6. **Citas de fuentes**: Formato [1], [2], [3]
7. **Memoria operativa**: InformaciÃ³n aprendida del sistema

#### Ejemplo de Prompt Completo

```
Eres el Agente Interno Oficial de Capital Plus...

[Contexto recuperado de la base de conocimientos:]
[Fuente 1: documento.pdf, PÃ¡gina 5]
Texto del chunk 1...

[Fuente 2: documento2.pdf, PÃ¡gina 3]
Texto del chunk 2...

**INSTRUCCIONES IMPORTANTES SOBRE CITAS:**
- Cada fuente estÃ¡ numerada como "Fuente 1", "Fuente 2", etc.
- Cuando uses informaciÃ³n de una fuente, DEBES incluir una cita numÃ©rica [1], [2], etc.

Pregunta: [query del usuario]
```

### Memoria Operativa del Agente

El sistema mantiene una memoria de informaciÃ³n importante:

```typescript
// Cargar memorias con importancia >= 0.7
const memories = await getAgentMemories(0.7);

// Se agregan al system prompt como:
## ğŸ§  MEMORIA DEL SISTEMA
- **Tema 1**: Resumen de informaciÃ³n importante
- **Tema 2**: Otra informaciÃ³n relevante
```

---

## AutenticaciÃ³n y Seguridad

### Sistema de AutenticaciÃ³n JWT

#### Tokens

- **Access Token**: Expira en 24 horas (configurable)
- **Refresh Token**: Expira en 7 dÃ­as (configurable)
- **Secrets**: `JWT_SECRET` y `JWT_REFRESH_SECRET` (variables de entorno)

#### Flujo de Login

```
1. Usuario envÃ­a email y contraseÃ±a
   â†“
2. ValidaciÃ³n de formato de email
   â†“
3. Buscar usuario en PostgreSQL
   â†“
4. Verificar si cuenta estÃ¡ activa
   â†“
5. Verificar si cuenta estÃ¡ bloqueada (por intentos fallidos)
   â†“
6. Verificar contraseÃ±a con bcrypt
   â†“
7. Si falla:
   â†’ Incrementar intentos fallidos
   â†’ Si >= 5 intentos, bloquear cuenta por 15 minutos
   â†“
8. Si Ã©xito:
   â†’ Resetear intentos fallidos
   â†’ Actualizar Ãºltimo login
   â†’ Generar access token y refresh token
   â†’ Crear sesiÃ³n en base de datos
   â†“
9. Retornar tokens y datos del usuario
```

#### Seguridad de ContraseÃ±as

- **Hashing**: bcrypt con 12 rounds
- **ValidaciÃ³n de fortaleza**: MÃ­nimo 8 caracteres, mayÃºscula, minÃºscula, nÃºmero, carÃ¡cter especial
- **Bloqueo de cuenta**: 5 intentos fallidos â†’ bloqueo por 15 minutos

#### GestiÃ³n de Sesiones

Cada login crea una sesiÃ³n en `user_sessions` con:
- `session_token`: Access token
- `refresh_token`: Refresh token
- `expires_at`: Fecha de expiraciÃ³n
- `ip_address`: IP del cliente
- `user_agent`: Navegador del cliente

### Sistema de Roles y Permisos

#### Roles Predefinidos

1. **CEO**: Acceso total a todo
2. **Admin**: GestiÃ³n completa (usuarios, configuraciÃ³n, documentos)
3. **Sales Manager**: Upload, Query, View
4. **Sales Agent**: Query, View
5. **Post-Sales**: Query, View
6. **Legal Manager**: Upload, Query, View
7. **Marketing Manager**: Upload, Query, View

#### Permisos

- `query_agent`: Consultar al agente
- `upload_documents`: Subir documentos
- `manage_users`: Gestionar usuarios (solo admin/CEO)
- `view_logs`: Ver logs (solo admin/CEO)

#### Control de Acceso por Zona y Desarrollo

```typescript
// Verificar acceso a un desarrollo especÃ­fico
const hasAccess = await checkUserAccess(
  userId,
  zone,        // 'yucatan', 'puebla', etc.
  development, // 'riviera', 'campo_magno', etc.
  'can_query'  // o 'can_upload'
);
```

**Roles con acceso total** (no requieren asignaciÃ³n especÃ­fica):
- CEO
- Admin
- Legal Manager
- Post-Sales
- Marketing Manager

**Otros roles** requieren asignaciÃ³n explÃ­cita en `user_developments`.

---

## Base de Datos PostgreSQL

### Estructura de Tablas Principales

#### 1. `users`

```sql
- id (SERIAL PRIMARY KEY)
- email (VARCHAR UNIQUE)
- name (VARCHAR)
- role_id (INTEGER â†’ roles.id)
- password_hash (VARCHAR)
- is_active (BOOLEAN)
- failed_login_attempts (INTEGER)
- locked_until (TIMESTAMP)
- last_login (TIMESTAMP)
- created_at, updated_at
```

#### 2. `roles` y `permissions`

```sql
-- roles
- id, name, description

-- permissions
- id, name, description

-- role_permissions (many-to-many)
- role_id, permission_id
```

#### 3. `user_developments`

```sql
- user_id, zone, development
- can_upload (BOOLEAN)
- can_query (BOOLEAN)
- PRIMARY KEY (user_id, zone, development)
```

#### 4. `documents_meta`

```sql
- id, filename, zone, development, type
- uploaded_by, pinecone_namespace
- tags (TEXT[]), created_at
```

#### 5. `query_logs`

```sql
- id, user_id, query, zone, development
- response, sources_used (TEXT[])
- response_time_ms, tokens_used
- feedback_rating, feedback_comment
- created_at
```

#### 6. `query_cache`

```sql
- id, query_text, query_hash
- zone, development, document_type
- response, sources_used (TEXT[])
- embedding_id, hit_count
- last_used_at, created_at, expires_at
```

#### 7. `chunk_stats`

```sql
- chunk_id (PRIMARY KEY)
- success_count, fail_count
- last_used (TIMESTAMP)
```

#### 8. `agent_memory`

```sql
- topic (PRIMARY KEY)
- summary (TEXT)
- importance (NUMERIC 0-1)
- last_updated (TIMESTAMP)
```

#### 9. `user_sessions`

```sql
- id, user_id
- session_token, refresh_token
- expires_at, last_used_at
- ip_address, user_agent
```

### ConexiÃ³n a PostgreSQL

#### ConfiguraciÃ³n de Pool

```typescript
// UbicaciÃ³n: src/lib/postgres.ts

// Prioridad de variables de entorno:
1. DATABASE_URL (manual - recomendado)
2. POSTGRES_URL_NON_POOLING (Vercel auto)
3. POSTGRES_PRISMA_URL (Vercel auto)
4. POSTGRES_URL (pooler - puede fallar en serverless)
5. Variables individuales (desarrollo local)

// ConfiguraciÃ³n para Supabase:
{
  host, port, user, password, database,
  ssl: { rejectUnauthorized: false },
  family: 4  // Forzar IPv4 (Vercel no soporta IPv6)
}
```

#### Pool de Conexiones

- **MÃ¡ximo**: 20 conexiones
- **Idle Timeout**: 30 segundos
- **Connection Timeout**: 10 segundos

### Funciones Principales de PostgreSQL

#### Usuarios

- `getUserById()`, `getUserByEmail()`
- `createUser()`, `updateUser()`
- `checkUserAccess()` - Verificar permisos por zona/desarrollo
- `hasPermission()` - Verificar permiso especÃ­fico

#### Documentos

- `saveDocumentMeta()` - Guardar metadata
- `getDocuments()` - Listar con filtros
- `deleteDocument()` - Eliminar documento

#### Logs y CachÃ©

- `saveQueryLog()` - Guardar consulta
- `getQueryLogs()` - Listar con paginaciÃ³n
- `getCachedResponse()` - Buscar en cachÃ©
- `saveCachedResponse()` - Guardar en cachÃ©

#### Aprendizaje

- `updateChunkStats()` - Actualizar estadÃ­sticas de chunks
- `registerQueryChunks()` - Registrar chunks usados
- `getAgentMemories()` - Obtener memoria del agente
- `upsertAgentMemory()` - Guardar/actualizar memoria

---

## Proveedores LLM

### Arquitectura de AbstracciÃ³n

El sistema usa una capa de abstracciÃ³n que permite cambiar entre proveedores:

```typescript
// UbicaciÃ³n: src/lib/llm-provider.ts

getLLMProvider() â†’ Lee de agent_config (llm_provider)
  â†“
runLLM() â†’ Llama al proveedor configurado
  â†“
  â”œâ”€â†’ LM Studio (local)
  â””â”€â†’ OpenAI (cloud)
```

### ConfiguraciÃ³n DinÃ¡mica

El proveedor se configura en la base de datos:

```sql
INSERT INTO agent_config (key, value) 
VALUES ('llm_provider', 'lmstudio'); -- o 'openai'
```

### LM Studio (Local)

#### ConfiguraciÃ³n

```env
LMSTUDIO_BASE_URL=http://localhost:1234/v1
LMSTUDIO_MODEL=llama-3.2-3B-Instruct-Q4_K_M
```

#### ImplementaciÃ³n

```typescript
// UbicaciÃ³n: src/lib/lmstudio.ts

const response = await fetch(`${baseUrl}/chat/completions`, {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    model: model,
    messages: messages,
    temperature: temperature,
    max_tokens: max_tokens,
  })
});
```

#### Health Check

```typescript
// Verifica que el servidor estÃ© disponible
const health = await fetch(`${baseUrl}/models`);
return health.ok;
```

### OpenAI (Cloud)

#### ConfiguraciÃ³n

```env
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
```

#### ImplementaciÃ³n

```typescript
// UbicaciÃ³n: src/lib/openai.ts

const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

const completion = await openai.chat.completions.create({
  model: model,
  messages: messages,
  temperature: temperature,
  max_tokens: max_tokens,
});
```

### ParÃ¡metros del LLM

- **Temperature**: 0.2 (default) - Controla creatividad (0.0 = determinista, 1.0 = creativo)
- **Max Tokens**: 2048 (default) - LÃ­mite de tokens en respuesta
- **Model**: Configurable por proveedor

### Funciones de Alto Nivel

#### `runRAGQuery()`

```typescript
// Construye el prompt completo con:
// 1. System prompt (con memorias)
// 2. Contexto recuperado
// 3. Query del usuario
// 4. Instrucciones de citas
```

#### `runSimpleQuery()`

```typescript
// Para consultas simples (saludos)
// Usa un prompt mÃ¡s corto y creativo
// Temperature: 0.7, Max Tokens: 150
```

---

## Sistema de CachÃ©

### Arquitectura de CachÃ©

El sistema usa un cachÃ© de dos niveles:

1. **CachÃ© en Memoria** (embeddings): Map en memoria del servidor
2. **CachÃ© en PostgreSQL + Pinecone**: Persistente

### Flujo de CachÃ©

```
1. Usuario hace consulta
   â†“
2. Generar hash MD5 del query normalizado
   â†“
3. Buscar en PostgreSQL por hash exacto
   â†“
4. Si no encuentra:
   â†’ Generar embedding del query
   â†’ Buscar en Pinecone (namespace: cache) por similitud
   â†’ Si similarity >= 0.85, usar respuesta del cachÃ©
   â†“
5. Si encuentra:
   â†’ Incrementar hit_count
   â†’ Retornar respuesta
   â†“
6. Si no encuentra:
   â†’ Procesar consulta normalmente
   â†’ Guardar respuesta en cachÃ©
```

### Estructura del CachÃ©

#### PostgreSQL (`query_cache`)

```sql
- query_text: Query normalizado
- query_hash: MD5 del query
- zone, development, document_type
- response: Respuesta completa
- sources_used: Array de nombres de archivos
- embedding_id: ID del vector en Pinecone
- hit_count: NÃºmero de veces usado
- expires_at: Fecha de expiraciÃ³n (30 dÃ­as)
```

#### Pinecone (namespace: `cache`)

```typescript
{
  id: `cache-${queryHash}`,
  values: embeddingVector, // Vector de 1024 dimensiones
  metadata: {
    query_text: normalizedQuery,
    zone, development, document_type,
    query_hash: queryHash
  }
}
```

### BÃºsqueda SemÃ¡ntica en CachÃ©

```typescript
// 1. Generar embedding del query
const embeddings = await client.inference.embed(
  'llama-text-embed-v2',
  [normalizedQuery],
  { inputType: 'query' }
);

// 2. Buscar en Pinecone
const response = await ns.query({
  vector: queryVector,
  topK: 3,
  filter: { zone, development, document_type },
  includeMetadata: true
});

// 3. Si similarity >= 0.85, usar respuesta
if (bestMatch.score >= 0.85) {
  // Buscar entrada en PostgreSQL por embedding_id
  const entry = await getSimilarCachedResponses([embeddingId], ...);
  return entry;
}
```

### CachÃ© de Embeddings en Memoria

Para evitar regenerar embeddings del mismo query:

```typescript
const embeddingCache = new Map<string, {
  vector: number[];
  timestamp: number;
}>();

// TTL: 1 hora
// LÃ­mite: 100 entradas (LRU)
```

### Limpieza de CachÃ©

- **ExpiraciÃ³n automÃ¡tica**: 30 dÃ­as
- **Limpieza manual**: `cleanupExpiredCache()`
- **CachÃ© en memoria**: LRU (mantiene Ãºltimas 100 entradas)

---

## Sistema de Aprendizaje

### Componentes del Sistema de Aprendizaje

1. **Chunk Stats**: EstadÃ­sticas de Ã©xito/fallo de chunks
2. **Agent Memory**: Memoria operativa del agente
3. **Response Learning**: Aprendizaje de respuestas
4. **Feedback Processing**: Procesamiento de feedback de usuarios

### Chunk Stats

#### ActualizaciÃ³n de EstadÃ­sticas

```typescript
// Cuando un usuario da feedback:
if (rating >= 4) {
  // Ã‰xito: incrementar success_count
  await query(`
    INSERT INTO chunk_stats (chunk_id, success_count)
    VALUES ($1, 1)
    ON CONFLICT DO UPDATE SET
      success_count = chunk_stats.success_count + 1
  `);
} else if (rating <= 2) {
  // Falla: incrementar fail_count
  await query(`
    INSERT INTO chunk_stats (chunk_id, fail_count)
    VALUES ($1, 1)
    ON CONFLICT DO UPDATE SET
      fail_count = chunk_stats.fail_count + 1
  `);
}
```

#### Uso en Re-ranking

```typescript
// Calcular success_ratio
const successRatio = success_count / (success_count + fail_count);

// Aplicar en score final
const finalScore = (similarityScore * 0.8) + (successRatio * 0.2);
```

Esto hace que chunks que han sido Ãºtiles tengan mayor prioridad en futuras bÃºsquedas.

### Agent Memory

#### Estructura

```sql
agent_memory:
- topic (PRIMARY KEY): Tema de la memoria
- summary: Resumen de la informaciÃ³n
- importance: 0.0 - 1.0 (importancia)
- last_updated: Fecha de Ãºltima actualizaciÃ³n
```

#### Uso

Las memorias con `importance >= 0.7` se incluyen automÃ¡ticamente en el system prompt:

```typescript
const memories = await getAgentMemories(0.7);

// Se agregan al prompt como:
## ğŸ§  MEMORIA DEL SISTEMA
- **Tema 1**: Resumen...
- **Tema 2**: Resumen...
```

#### ActualizaciÃ³n

```typescript
// Crear o actualizar memoria
await upsertAgentMemory(
  topic: string,
  summary: string,
  importance: number
);

// La importancia se promedia si ya existe
importance = (oldImportance + newImportance) / 2;
```

### Response Learning

El sistema puede aprender respuestas completas para queries frecuentes:

```sql
response_learning:
- query (PRIMARY KEY): Query exacto
- answer: Respuesta aprendida
- quality_score: 0.0 - 1.0 (calidad)
- usage_count: NÃºmero de veces usada
- last_improved_at: Fecha de Ãºltima mejora
```

**Nota**: Esta funcionalidad estÃ¡ implementada pero no se usa activamente en el flujo principal.

### Feedback Processing

#### Flujo de Feedback

```
1. Usuario da feedback (rating 1-5, comentario opcional)
   â†“
2. Guardar en query_logs (feedback_rating, feedback_comment)
   â†“
3. Actualizar chunk_stats para cada chunk usado
   â†“
4. (Opcional) Procesar para mejorar respuestas futuras
```

#### Script de Procesamiento

```bash
# Procesar feedback reciente (Ãºltimas 24 horas)
node scripts/process-feedback-learning.js
```

Este script:
- Obtiene feedback reciente
- Analiza patrones
- Actualiza memorias del agente
- Mejora respuestas aprendidas

---

## Flujos Completos

### Flujo 1: Upload de Documento

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Usuario   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. POST /api/upload
       â”‚    (file, zone, development, type)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ValidaciÃ³n      â”‚
â”‚  - TamaÃ±o        â”‚
â”‚  - Tipo          â”‚
â”‚  - Permisos      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ExtracciÃ³n      â”‚
â”‚  - PDF: pdf-parseâ”‚
â”‚  - CSV: parse    â”‚
â”‚  - DOCX: mammoth â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Limpieza        â”‚
â”‚  - Normalizar    â”‚
â”‚  - Limpiar       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Chunking        â”‚
â”‚  - Dividir       â”‚
â”‚  - Overlap       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Embeddings      â”‚
â”‚  Pinecone        â”‚
â”‚  Inference API   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pinecone        â”‚
â”‚  - Upsert        â”‚
â”‚  - Metadata      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL      â”‚
â”‚  - documents_metaâ”‚
â”‚  - action_logs   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Respuesta  â”‚
â”‚  (success)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo 2: Consulta RAG

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Usuario   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. POST /api/rag-query
       â”‚    (query, zone, development)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AutenticaciÃ³n   â”‚
â”‚  - Verificar JWT â”‚
â”‚  - Permisos      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Â¿Consulta       â”‚
â”‚  Simple?         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
   â”Œâ”€â”€â”€â”´â”€â”€â”€â”
   â”‚       â”‚
  SÃ      NO
   â”‚       â”‚
   â–¼       â–¼
â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM â”‚ â”‚  Buscar CachÃ©    â”‚
â”‚Simpleâ”‚ â”‚  - Hash exacto   â”‚
â””â”€â”€â”€â”€â”€â”˜ â”‚  - Similitud     â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
          â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
          â”‚         â”‚
        HIT       MISS
          â”‚         â”‚
          â–¼         â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Retornarâ”‚ â”‚  Procesar Query  â”‚
    â”‚ CachÃ©   â”‚ â”‚  - CorrecciÃ³n    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  - ExpansiÃ³n     â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Embedding Query â”‚
                â”‚  Pinecone        â”‚
                â”‚  Inference API   â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Buscar Pinecone â”‚
                â”‚  - Query vector  â”‚
                â”‚  - Filtros       â”‚
                â”‚  - TopK          â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Re-ranking      â”‚
                â”‚  - Chunk stats   â”‚
                â”‚  - Score final   â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Construir       â”‚
                â”‚  Contexto        â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Cargar Memorias â”‚
                â”‚  Agent Memory    â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  LLM             â”‚
                â”‚  - System prompt â”‚
                â”‚  - Contexto      â”‚
                â”‚  - Query         â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Construir       â”‚
                â”‚  Fuentes         â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Guardar CachÃ©   â”‚
                â”‚  - PostgreSQL    â”‚
                â”‚  - Pinecone      â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Guardar Log     â”‚
                â”‚  - query_logs    â”‚
                â”‚  - chunks usados â”‚
                â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Respuesta  â”‚
                â”‚  + Fuentes  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Flujo 3: Feedback y Aprendizaje

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Usuario   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ 1. POST /api/rag-feedback
       â”‚    (query_log_id, rating, comment)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Guardar Feedbackâ”‚
â”‚  - query_logs    â”‚
â”‚  - rating        â”‚
â”‚  - comment       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Obtener Chunks  â”‚
â”‚  Usados          â”‚
â”‚  - query_logs_   â”‚
â”‚    chunks        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Actualizar      â”‚
â”‚  Chunk Stats     â”‚
â”‚  - success_count â”‚
â”‚  - fail_count    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  (Opcional)      â”‚
â”‚  Procesar        â”‚
â”‚  Aprendizaje     â”‚
â”‚  - Memorias      â”‚
â”‚  - Respuestas    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Conexiones y ConfiguraciÃ³n

### Variables de Entorno Requeridas

#### Base de Datos

```env
# OpciÃ³n 1: Cadena de conexiÃ³n completa (recomendado)
DATABASE_URL=postgresql://user:password@host:5432/database

# OpciÃ³n 2: Variables individuales (desarrollo local)
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=postgres
POSTGRES_PASSWORD=password
POSTGRES_DB=capital_plus_agent
```

#### Pinecone

```env
PINECONE_API_KEY=tu-api-key-aqui
PINECONE_INDEX_NAME=capitalplus-rag
```

**Importante**: El Ã­ndice debe tener **1024 dimensiones** (llama-text-embed-v2).

#### LLM

```env
# LM Studio (local)
LMSTUDIO_BASE_URL=http://localhost:1234/v1
LMSTUDIO_MODEL=llama-3.2-3B-Instruct-Q4_K_M

# OpenAI (cloud)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini
```

#### AutenticaciÃ³n

```env
JWT_SECRET=tu-secret-key-muy-segura
JWT_REFRESH_SECRET=tu-refresh-secret-key
JWT_EXPIRES_IN=24h
JWT_REFRESH_EXPIRES_IN=7d
```

#### Otros

```env
UPLOAD_DIR=./tmp
MAX_FILE_SIZE=52428800  # 50MB
CHUNK_SIZE=500
CHUNK_OVERLAP=50
```

### ConfiguraciÃ³n de Pinecone

#### Crear Ãndice

1. Ve a [Pinecone Console](https://app.pinecone.io/)
2. Crea un nuevo Ã­ndice:
   - **Name**: `capitalplus-rag`
   - **Dimensions**: `1024` âš ï¸
   - **Metric**: `cosine`
   - **Cloud**: AWS
   - **Region**: us-east-1

#### Verificar ConfiguraciÃ³n

```typescript
// Verificar que el Ã­ndice existe y tiene las dimensiones correctas
const index = await getPineconeIndex();
const stats = await index.describeIndexStats();
console.log(stats);
```

### ConfiguraciÃ³n de PostgreSQL

#### Migraciones

```bash
# Ejecutar todas las migraciones
npm run db:migrate:all

# Migraciones disponibles:
# - 001_initial_schema.sql
# - 002_action_logs.sql
# - 002_update_roles.sql
# - 003_add_auth_fields.sql
# - 003_query_cache.sql
# - 004_cache_indexes_optimization.sql
# - 004_learning_system.sql
# - 005_add_feedback_rating.sql
# - 006_llm_provider_config.sql
```

#### Seed de Datos

```bash
# Insertar datos iniciales (roles, permisos, usuario admin)
npm run db:seed

# Configurar contraseÃ±a de admin
npm run db:set-admin-password
```

### ConfiguraciÃ³n de Supabase (Vercel)

#### Variables de Entorno en Vercel

1. Ve a Vercel Dashboard â†’ Settings â†’ Environment Variables
2. Agrega `DATABASE_URL` con la cadena de conexiÃ³n de Supabase:
   - Supabase Dashboard â†’ Settings â†’ Database â†’ Connection String
   - Usa "Direct connection" (no pooler)

#### ConfiguraciÃ³n SSL

El cÃ³digo automÃ¡ticamente detecta Supabase y configura SSL:

```typescript
ssl: {
  rejectUnauthorized: false  // Necesario para Supabase
}
```

#### Forzar IPv4

Vercel no soporta IPv6, por lo que se fuerza IPv4:

```typescript
family: 4  // Forzar IPv4
```

---

## Resumen de MÃ©todos y Funciones Clave

### Pinecone (`src/lib/pinecone.ts`)

- `initPinecone()`: Inicializar cliente
- `getPineconeIndex()`: Obtener Ã­ndice
- `upsertChunks()`: Subir chunks con embeddings
- `queryChunks()`: Buscar chunks similares
- `buildContextFromMatches()`: Construir contexto desde matches
- `deleteDocumentChunks()`: Eliminar chunks de un documento

### PostgreSQL (`src/lib/postgres.ts`)

- `getUserById()`, `getUserByEmail()`: Obtener usuarios
- `checkUserAccess()`: Verificar permisos
- `saveDocumentMeta()`: Guardar metadata de documentos
- `saveQueryLog()`: Guardar log de consulta
- `getCachedResponse()`: Buscar en cachÃ©
- `getAgentMemories()`: Obtener memoria del agente
- `updateChunkStats()`: Actualizar estadÃ­sticas

### LLM (`src/lib/llm.ts`, `src/lib/llm-provider.ts`)

- `runLLM()`: Ejecutar consulta al LLM
- `runRAGQuery()`: Consulta RAG completa
- `runSimpleQuery()`: Consulta simple (sin RAG)
- `getLLMProvider()`: Obtener proveedor configurado
- `checkLLMHealth()`: Verificar salud del LLM

### Chunking (`src/lib/chunker.ts`)

- `chunkText()`: Dividir texto en chunks
- `createChunksWithMetadata()`: Crear chunks con metadata
- `createPageAwareChunks()`: Chunks con informaciÃ³n de pÃ¡gina
- `estimateTokens()`: Estimar tokens en texto

### Query Processing (`src/lib/queryProcessing.ts`)

- `processQuery()`: Procesar query completo
- `correctSpelling()`: Corregir ortografÃ­a
- `expandQuerySemantically()`: Expandir semÃ¡nticamente
- `generateQueryVariants()`: Generar variantes

### Cache (`src/lib/cache.ts`)

- `findCachedResponse()`: Buscar respuesta en cachÃ©
- `saveToCache()`: Guardar respuesta en cachÃ©
- `cleanupCache()`: Limpiar cachÃ© expirado

### Auth (`src/lib/auth.ts`)

- `hashPassword()`: Hashear contraseÃ±a
- `verifyPassword()`: Verificar contraseÃ±a
- `generateAccessToken()`: Generar access token
- `verifyAccessToken()`: Verificar access token
- `validateEmail()`: Validar formato de email

---

## ConclusiÃ³n

Este sistema implementa un RAG completo y robusto con:

- âœ… **BÃºsqueda semÃ¡ntica** con embeddings vectoriales
- âœ… **Procesamiento inteligente** de documentos
- âœ… **CachÃ© optimizado** para respuestas rÃ¡pidas
- âœ… **Sistema de aprendizaje** que mejora con el tiempo
- âœ… **AutenticaciÃ³n segura** con JWT
- âœ… **Control de acceso granular** por zona y desarrollo
- âœ… **MÃºltiples proveedores LLM** (local y cloud)
- âœ… **Logging completo** para anÃ¡lisis y debugging

El sistema estÃ¡ diseÃ±ado para escalar y mejorar continuamente basÃ¡ndose en el feedback de los usuarios y las estadÃ­sticas de uso.

---

**Ãšltima actualizaciÃ³n**: 2024
**VersiÃ³n del documento**: 1.0

